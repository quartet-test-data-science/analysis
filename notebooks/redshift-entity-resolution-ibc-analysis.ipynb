{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee2699ee",
   "metadata": {},
   "source": [
    "# redshift-entity-resolution-ibc-analysis\n",
    "\n",
    "An analysis of possibly missing members in IBC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7374bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import environ\n",
    "import io\n",
    "from operator import itemgetter\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "import s3fs\n",
    "import io\n",
    "import boto3\n",
    "import gzip\n",
    "import fastparquet as fp\n",
    "import awswrangler as wr\n",
    "import redshift_connector\n",
    "from s3fs import S3FileSystem\n",
    "from fastparquet import ParquetFile\n",
    "from sqlalchemy.engine import create_engine\n",
    "from pandas.io.sql import SQLTable\n",
    "\n",
    "from helpers import (\n",
    "    save_dataframe_csv,\n",
    "    get_training_data,\n",
    "    parquet_file,\n",
    "    parquet_dataframe,\n",
    "    make_dataframe_db_schema,\n",
    "    download_from_s3,\n",
    "    save_manifest_s3,\n",
    "    save_data_qa,\n",
    "    save_json_s3\n",
    ")\n",
    "\n",
    "dsn = create_engine(environ[\"ANALYTICS\"])\n",
    "\n",
    "pd.options.display.max_columns = 500\n",
    "pd.options.display.max_rows = 500\n",
    "\n",
    "log = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c22b7",
   "metadata": {},
   "source": [
    "## Reading csv files from from S3\n",
    "\n",
    "Simple as pie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ba2760",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = s3fs.S3FileSystem(anon=False)\n",
    "\n",
    "df_raw = pd.read_csv(\n",
    "    's3://qh-clinicaldata-phi/raw_feed/pre_ingest/healthy_blue/y=2022/m=03/d=10/'\n",
    "    'ts=134943/QUARTET_GBDFACETS_PATIENT_20220310.txt',\n",
    "    delimiter=\"|\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cd1c46",
   "metadata": {},
   "source": [
    "## Redshift operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e84e8ba",
   "metadata": {},
   "source": [
    "Query data in redshift and put it into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2af53b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_scope_query = \"\"\"\n",
    "SELECT DISTINCT\n",
    "       \"case\".patient__birthdate__c AS dob\n",
    "     , \"account\".name\n",
    "     , \"case\".insurance__plans__c AS sf_plan\n",
    "     , \"case\".most__recent__referred__date__c\n",
    "     , \"case\".activation__channel__c\n",
    "     , \"case\".case__closed__reason__c\n",
    "     , account.patient__claims__data__c\n",
    "     , account.quartet_id__c AS patient_id\n",
    "FROM salesforce.\"case\"\n",
    "LEFT JOIN salesforce.account\n",
    "  ON account.id = \"case\".account_id\n",
    "WHERE \"case\".created_date BETWEEN '2024-01-01' AND '2025-01-01'\n",
    "  AND \"case\".insurance__category__c NOT IN ('Medicare', 'Medicaid')\n",
    "  AND account.patient__claims__data__c IS NULL\n",
    "  AND (\n",
    "      \"case\".insurance__plans__c ILIKE '%%Independence%%'\n",
    "   OR \"case\".insurance__plans__c ILIKE '%%Amerihealth%%'\n",
    "    )\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d10281af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_scope_df = pd.read_sql(sf_scope_query, dsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2a7de797",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_scope_df['first_name'] = sf_scope_df['name'].apply(lambda x: x.split()[0])\n",
    "sf_scope_df['last_name'] = sf_scope_df['name'].apply(lambda x: ' '.join(x.split()[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d02ed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = []\n",
    "\n",
    "for i, row in sf_scope_df.iterrows():\n",
    "    if True:\n",
    "        dob = row['dob']\n",
    "        first_name = row['first_name']\n",
    "        last_name = row['last_name']\n",
    "        patient_id = row['patient_id']\n",
    "        sf_plan = row['sf_plan']\n",
    "        query = f'''\n",
    "            SELECT DISTINCT\n",
    "                UPPER(mm.member_first_name) AS member_first_name\n",
    "              , UPPER(mm.member_last_name) AS member_last_name\n",
    "              , mm.member_dob\n",
    "              , mm.member_id\n",
    "              , TRUE AS found_in_member_file\n",
    "              , '{patient_id}' AS patient_id\n",
    "              , '{sf_plan}' AS sf_plan\n",
    "              , pi.insurance_carrier\n",
    "              , pi.insurance_plan\n",
    "              , pi.card_ids\n",
    "            FROM independence_prod.member_month AS mm\n",
    "            LEFT JOIN independence_prod.patient_insurance AS pi\n",
    "              ON pi.patient_insurance_quid = mm.patient_insurance_quid\n",
    "            WHERE member_dob = '{dob}'\n",
    "              AND member_first_name ILIKE '%%{first_name}%%'\n",
    "              AND member_last_name ILIKE '%%{last_name}%%'\n",
    "            '''\n",
    "        row_df = pd.read_sql(query, dsn)\n",
    "        if row_df.empty:\n",
    "            row_df = pd.DataFrame(\n",
    "                {\n",
    "                    'member_first_name': first_name.upper(),\n",
    "                    'member_last_name': last_name.upper(),\n",
    "                    'member_dob': dob,\n",
    "                    'member_id': '',\n",
    "                    'patient_id': patient_id,\n",
    "                    'found_in_member_file': False,\n",
    "                    'sf_plan': sf_plan,\n",
    "                    'insurance_carrier': '',\n",
    "                    'insurance_plan': '',\n",
    "                    'card_ids': ''\n",
    "                }, index = [0]\n",
    "            )\n",
    "        data_df.append(row_df)\n",
    "\n",
    "missing_data_df = pd.concat(data_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0910f320",
   "metadata": {},
   "source": [
    "Put data into a table in redshift (connector for awswrangler is different than sqlalchemy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae9772",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_name = 'ahmiel'\n",
    "table_name = 'ibc_missing_sf_claims_members_lookup'\n",
    "\n",
    "connector = redshift_connector.connect(\n",
    "    host=environ['PGHOST'],\n",
    "    database=environ['PGDATABASE'],\n",
    "    user=environ['PGUSER'],\n",
    "    password=environ['PGPASSWORD']\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cea4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "wr.redshift.to_sql(\n",
    "        df=missing_data_df,\n",
    "        table=table_name,\n",
    "        schema=schema_name,\n",
    "        con=connector,\n",
    "        mode='overwrite',\n",
    "        dtype={'value': 'VARCHAR(5)'},\n",
    "        overwrite_method='drop',\n",
    "        index=False,\n",
    "        chunksize=1000\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb84897",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
